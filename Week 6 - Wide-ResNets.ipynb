{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJW9DxhT35hy+OBZ1SJV/n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"U8QDj-xm09cd"},"outputs":[],"source":["## Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","source":["# Comparison of ResNets and Wide-ResNets\n","#\n","# | Feature        | ResNet                                  | Wide ResNet                             |\n","# |----------------|------------------------------------------|-----------------------------------------|\n","# | Architecture   | Uses residual blocks with skip connections | Uses wider residual blocks              |\n","# | Width          | Relatively narrow                        | Increased width of convolutional layers |\n","# | Depth          | Can be very deep                         | Can be relatively shallower              |\n","# | Computational Cost | Lower                                  | Higher                                 |\n","# | Accuracy       | High, but can plateau with increasing depth | Often achieves higher accuracy for similar depth|\n","# | Memory Usage   | Lower                                  | Higher                                 |\n","# | Training Time  | Lower                                  | Higher                                 |\n","# | Advantages     | Efficient, good performance              | Higher accuracy, potentially better generalization |\n","# | Disadvantages  | Accuracy may saturate at very high depths| Higher computational and memory overhead |\n","# | Use Cases      | General purpose image classification     | Applications requiring high accuracy with limited depth |"],"metadata":{"id":"033Tv_cB6r5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ResNets"],"metadata":{"id":"ZBvIer9SkbMm"}},{"cell_type":"code","source":["# Define a Basic Residual Block (Used in both ResNet and Wide-ResNet)\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","        return out"],"metadata":{"id":"EUY2Wi8u1IVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standard ResNet (Narrow and Deep)\n","class ResNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.layer1 = self._make_layer(3, 64, 2)\n","        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n","        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        layers = [ResidualBlock(in_channels, out_channels, stride, downsample)]\n","        for _ in range(1, blocks):\n","            layers.append(ResidualBlock(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"0E-lX3Cz1GY7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Wide-ResNets"],"metadata":{"id":"eC8ZzyE2keGi"}},{"cell_type":"code","source":["# Wide ResNet (Wider instead of Deeper)\n","class WideResNet(nn.Module):\n","    def __init__(self, num_classes=10, width_factor=2):  # Width factor increases channels\n","        super(WideResNet, self).__init__()\n","        self.layer1 = self._make_layer(3, 64 * width_factor, 2)\n","        self.layer2 = self._make_layer(64 * width_factor, 128 * width_factor, 2, stride=2)\n","        self.layer3 = self._make_layer(128 * width_factor, 256 * width_factor, 2, stride=2)\n","        self.layer4 = self._make_layer(256 * width_factor, 512 * width_factor, 2, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * width_factor, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        layers = [ResidualBlock(in_channels, out_channels, stride, downsample)]\n","        for _ in range(1, blocks):\n","            layers.append(ResidualBlock(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"yUVFB8GB1D_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from torchsummary import summary\n","import pandas as pd\n","\n","# Assuming you have defined your models (ResNet and WideResNet) as in the previous response.\n","\n","# Create instances of your models\n","resnet_model = ResNet()\n","wideresnet_model = WideResNet()\n","\n","# Get summaries for both models\n","resnet_summary = summary(resnet_model, (3, 32, 32), device='cpu') # Replace with actual input shape\n","wideresnet_summary = summary(wideresnet_model, (3, 32, 32), device='cpu')\n","\n","# Extract the relevant information\n","resnet_summary_str = str(resnet_summary)\n","wideresnet_summary_str = str(wideresnet_summary)\n","\n","\n","# Function to extract layer details\n","def extract_layer_info(summary_str):\n","    lines = summary_str.splitlines()\n","    header_index = next((i for i, line in enumerate(lines) if 'Output Shape' in line), None)\n","    if header_index is None:\n","        return []  # Or handle the error appropriately\n","\n","    layer_info = []\n","    for line in lines[header_index + 1:]:\n","        parts = line.split()\n","        if len(parts) > 3: # Check to avoid blank lines\n","          layer_info.append([parts[0], parts[2]])\n","\n","    return layer_info\n","\n","# Extract layer information for each model\n","resnet_layers = extract_layer_info(resnet_summary_str)\n","wideresnet_layers = extract_layer_info(wideresnet_summary_str)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EL-qVTVO1vyG","executionInfo":{"status":"ok","timestamp":1739141625976,"user_tz":300,"elapsed":2827,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}},"outputId":"3359a0c5-4e00-4fd3-f051-e3e851eaeace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]             192\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","              ReLU-5           [-1, 64, 32, 32]               0\n","            Conv2d-6           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-7           [-1, 64, 32, 32]             128\n","              ReLU-8           [-1, 64, 32, 32]               0\n","     ResidualBlock-9           [-1, 64, 32, 32]               0\n","           Conv2d-10           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","             ReLU-12           [-1, 64, 32, 32]               0\n","           Conv2d-13           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-14           [-1, 64, 32, 32]             128\n","             ReLU-15           [-1, 64, 32, 32]               0\n","    ResidualBlock-16           [-1, 64, 32, 32]               0\n","           Conv2d-17          [-1, 128, 16, 16]           8,192\n","      BatchNorm2d-18          [-1, 128, 16, 16]             256\n","           Conv2d-19          [-1, 128, 16, 16]          73,728\n","      BatchNorm2d-20          [-1, 128, 16, 16]             256\n","             ReLU-21          [-1, 128, 16, 16]               0\n","           Conv2d-22          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","             ReLU-24          [-1, 128, 16, 16]               0\n","    ResidualBlock-25          [-1, 128, 16, 16]               0\n","           Conv2d-26          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-27          [-1, 128, 16, 16]             256\n","             ReLU-28          [-1, 128, 16, 16]               0\n","           Conv2d-29          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-30          [-1, 128, 16, 16]             256\n","             ReLU-31          [-1, 128, 16, 16]               0\n","    ResidualBlock-32          [-1, 128, 16, 16]               0\n","           Conv2d-33            [-1, 256, 8, 8]          32,768\n","      BatchNorm2d-34            [-1, 256, 8, 8]             512\n","           Conv2d-35            [-1, 256, 8, 8]         294,912\n","      BatchNorm2d-36            [-1, 256, 8, 8]             512\n","             ReLU-37            [-1, 256, 8, 8]               0\n","           Conv2d-38            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-39            [-1, 256, 8, 8]             512\n","             ReLU-40            [-1, 256, 8, 8]               0\n","    ResidualBlock-41            [-1, 256, 8, 8]               0\n","           Conv2d-42            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-43            [-1, 256, 8, 8]             512\n","             ReLU-44            [-1, 256, 8, 8]               0\n","           Conv2d-45            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-46            [-1, 256, 8, 8]             512\n","             ReLU-47            [-1, 256, 8, 8]               0\n","    ResidualBlock-48            [-1, 256, 8, 8]               0\n","           Conv2d-49            [-1, 512, 4, 4]         131,072\n","      BatchNorm2d-50            [-1, 512, 4, 4]           1,024\n","           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n","             ReLU-53            [-1, 512, 4, 4]               0\n","           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n","             ReLU-56            [-1, 512, 4, 4]               0\n","    ResidualBlock-57            [-1, 512, 4, 4]               0\n","           Conv2d-58            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-59            [-1, 512, 4, 4]           1,024\n","             ReLU-60            [-1, 512, 4, 4]               0\n","           Conv2d-61            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-62            [-1, 512, 4, 4]           1,024\n","             ReLU-63            [-1, 512, 4, 4]               0\n","    ResidualBlock-64            [-1, 512, 4, 4]               0\n","AdaptiveAvgPool2d-65            [-1, 512, 1, 1]               0\n","           Linear-66                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,137,290\n","Trainable params: 11,137,290\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 15.00\n","Params size (MB): 42.49\n","Estimated Total Size (MB): 57.50\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 128, 32, 32]             384\n","       BatchNorm2d-2          [-1, 128, 32, 32]             256\n","            Conv2d-3          [-1, 128, 32, 32]           3,456\n","       BatchNorm2d-4          [-1, 128, 32, 32]             256\n","              ReLU-5          [-1, 128, 32, 32]               0\n","            Conv2d-6          [-1, 128, 32, 32]         147,456\n","       BatchNorm2d-7          [-1, 128, 32, 32]             256\n","              ReLU-8          [-1, 128, 32, 32]               0\n","     ResidualBlock-9          [-1, 128, 32, 32]               0\n","           Conv2d-10          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-11          [-1, 128, 32, 32]             256\n","             ReLU-12          [-1, 128, 32, 32]               0\n","           Conv2d-13          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-14          [-1, 128, 32, 32]             256\n","             ReLU-15          [-1, 128, 32, 32]               0\n","    ResidualBlock-16          [-1, 128, 32, 32]               0\n","           Conv2d-17          [-1, 256, 16, 16]          32,768\n","      BatchNorm2d-18          [-1, 256, 16, 16]             512\n","           Conv2d-19          [-1, 256, 16, 16]         294,912\n","      BatchNorm2d-20          [-1, 256, 16, 16]             512\n","             ReLU-21          [-1, 256, 16, 16]               0\n","           Conv2d-22          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-23          [-1, 256, 16, 16]             512\n","             ReLU-24          [-1, 256, 16, 16]               0\n","    ResidualBlock-25          [-1, 256, 16, 16]               0\n","           Conv2d-26          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-27          [-1, 256, 16, 16]             512\n","             ReLU-28          [-1, 256, 16, 16]               0\n","           Conv2d-29          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-30          [-1, 256, 16, 16]             512\n","             ReLU-31          [-1, 256, 16, 16]               0\n","    ResidualBlock-32          [-1, 256, 16, 16]               0\n","           Conv2d-33            [-1, 512, 8, 8]         131,072\n","      BatchNorm2d-34            [-1, 512, 8, 8]           1,024\n","           Conv2d-35            [-1, 512, 8, 8]       1,179,648\n","      BatchNorm2d-36            [-1, 512, 8, 8]           1,024\n","             ReLU-37            [-1, 512, 8, 8]               0\n","           Conv2d-38            [-1, 512, 8, 8]       2,359,296\n","      BatchNorm2d-39            [-1, 512, 8, 8]           1,024\n","             ReLU-40            [-1, 512, 8, 8]               0\n","    ResidualBlock-41            [-1, 512, 8, 8]               0\n","           Conv2d-42            [-1, 512, 8, 8]       2,359,296\n","      BatchNorm2d-43            [-1, 512, 8, 8]           1,024\n","             ReLU-44            [-1, 512, 8, 8]               0\n","           Conv2d-45            [-1, 512, 8, 8]       2,359,296\n","      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n","             ReLU-47            [-1, 512, 8, 8]               0\n","    ResidualBlock-48            [-1, 512, 8, 8]               0\n","           Conv2d-49           [-1, 1024, 4, 4]         524,288\n","      BatchNorm2d-50           [-1, 1024, 4, 4]           2,048\n","           Conv2d-51           [-1, 1024, 4, 4]       4,718,592\n","      BatchNorm2d-52           [-1, 1024, 4, 4]           2,048\n","             ReLU-53           [-1, 1024, 4, 4]               0\n","           Conv2d-54           [-1, 1024, 4, 4]       9,437,184\n","      BatchNorm2d-55           [-1, 1024, 4, 4]           2,048\n","             ReLU-56           [-1, 1024, 4, 4]               0\n","    ResidualBlock-57           [-1, 1024, 4, 4]               0\n","           Conv2d-58           [-1, 1024, 4, 4]       9,437,184\n","      BatchNorm2d-59           [-1, 1024, 4, 4]           2,048\n","             ReLU-60           [-1, 1024, 4, 4]               0\n","           Conv2d-61           [-1, 1024, 4, 4]       9,437,184\n","      BatchNorm2d-62           [-1, 1024, 4, 4]           2,048\n","             ReLU-63           [-1, 1024, 4, 4]               0\n","    ResidualBlock-64           [-1, 1024, 4, 4]               0\n","AdaptiveAvgPool2d-65           [-1, 1024, 1, 1]               0\n","           Linear-66                   [-1, 10]          10,250\n","================================================================\n","Total params: 44,515,850\n","Trainable params: 44,515,850\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 30.01\n","Params size (MB): 169.81\n","Estimated Total Size (MB): 199.83\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bX0rIB-Q4vmK"},"execution_count":null,"outputs":[]}]}