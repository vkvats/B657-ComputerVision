{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYzhamT9czeiyYyuTb58uA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n"],"metadata":{"id":"zBhOWBku8Bva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define ResNeXt Block with Grouped Convolutions\n","class ResNeXtBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, cardinality=32, stride=1, downsample=None):\n","        super(ResNeXtBlock, self).__init__()\n","        D = out_channels // 2  # Width per group\n","        self.conv1 = nn.Conv2d(in_channels, D * cardinality, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(D * cardinality)\n","        self.conv2 = nn.Conv2d(D * cardinality, D * cardinality, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n","        self.bn2 = nn.BatchNorm2d(D * cardinality)\n","        self.conv3 = nn.Conv2d(D * cardinality, out_channels, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out += identity\n","        out = self.relu(out)\n","        return out"],"metadata":{"id":"pOwG8RfWkuxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENinvYU_7p_U"},"outputs":[],"source":["# Define ResNeXt Network\n","class ResNeXt(nn.Module):\n","    def __init__(self, num_classes=10, cardinality=32):\n","        super(ResNeXt, self).__init__()\n","        self.layer1 = self._make_layer(3, 64, 3, cardinality)\n","        self.layer2 = self._make_layer(64, 128, 4, cardinality, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 6, cardinality, stride=2)\n","        self.layer4 = self._make_layer(256, 512, 3, cardinality, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, cardinality, stride=1):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        layers = [ResNeXtBlock(in_channels, out_channels, cardinality, stride, downsample)]\n","        for _ in range(1, blocks):\n","            layers.append(ResNeXtBlock(out_channels, out_channels, cardinality))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x\n"]},{"cell_type":"code","source":["# Instantiate and print model summary\n","model = ResNeXt()\n","summary(model, (3, 64, 64))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQu7XcDb7q0l","executionInfo":{"status":"ok","timestamp":1739142103532,"user_tz":300,"elapsed":4545,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}},"outputId":"9f680e11-b3c7-4085-d338-677af38ce62a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 64, 64]             192\n","       BatchNorm2d-2           [-1, 64, 64, 64]             128\n","            Conv2d-3         [-1, 1024, 64, 64]           3,072\n","       BatchNorm2d-4         [-1, 1024, 64, 64]           2,048\n","              ReLU-5         [-1, 1024, 64, 64]               0\n","            Conv2d-6         [-1, 1024, 64, 64]         294,912\n","       BatchNorm2d-7         [-1, 1024, 64, 64]           2,048\n","              ReLU-8         [-1, 1024, 64, 64]               0\n","            Conv2d-9           [-1, 64, 64, 64]          65,536\n","      BatchNorm2d-10           [-1, 64, 64, 64]             128\n","             ReLU-11           [-1, 64, 64, 64]               0\n","     ResNeXtBlock-12           [-1, 64, 64, 64]               0\n","           Conv2d-13         [-1, 1024, 64, 64]          65,536\n","      BatchNorm2d-14         [-1, 1024, 64, 64]           2,048\n","             ReLU-15         [-1, 1024, 64, 64]               0\n","           Conv2d-16         [-1, 1024, 64, 64]         294,912\n","      BatchNorm2d-17         [-1, 1024, 64, 64]           2,048\n","             ReLU-18         [-1, 1024, 64, 64]               0\n","           Conv2d-19           [-1, 64, 64, 64]          65,536\n","      BatchNorm2d-20           [-1, 64, 64, 64]             128\n","             ReLU-21           [-1, 64, 64, 64]               0\n","     ResNeXtBlock-22           [-1, 64, 64, 64]               0\n","           Conv2d-23         [-1, 1024, 64, 64]          65,536\n","      BatchNorm2d-24         [-1, 1024, 64, 64]           2,048\n","             ReLU-25         [-1, 1024, 64, 64]               0\n","           Conv2d-26         [-1, 1024, 64, 64]         294,912\n","      BatchNorm2d-27         [-1, 1024, 64, 64]           2,048\n","             ReLU-28         [-1, 1024, 64, 64]               0\n","           Conv2d-29           [-1, 64, 64, 64]          65,536\n","      BatchNorm2d-30           [-1, 64, 64, 64]             128\n","             ReLU-31           [-1, 64, 64, 64]               0\n","     ResNeXtBlock-32           [-1, 64, 64, 64]               0\n","           Conv2d-33          [-1, 128, 32, 32]           8,192\n","      BatchNorm2d-34          [-1, 128, 32, 32]             256\n","           Conv2d-35         [-1, 2048, 64, 64]         131,072\n","      BatchNorm2d-36         [-1, 2048, 64, 64]           4,096\n","             ReLU-37         [-1, 2048, 64, 64]               0\n","           Conv2d-38         [-1, 2048, 32, 32]       1,179,648\n","      BatchNorm2d-39         [-1, 2048, 32, 32]           4,096\n","             ReLU-40         [-1, 2048, 32, 32]               0\n","           Conv2d-41          [-1, 128, 32, 32]         262,144\n","      BatchNorm2d-42          [-1, 128, 32, 32]             256\n","             ReLU-43          [-1, 128, 32, 32]               0\n","     ResNeXtBlock-44          [-1, 128, 32, 32]               0\n","           Conv2d-45         [-1, 2048, 32, 32]         262,144\n","      BatchNorm2d-46         [-1, 2048, 32, 32]           4,096\n","             ReLU-47         [-1, 2048, 32, 32]               0\n","           Conv2d-48         [-1, 2048, 32, 32]       1,179,648\n","      BatchNorm2d-49         [-1, 2048, 32, 32]           4,096\n","             ReLU-50         [-1, 2048, 32, 32]               0\n","           Conv2d-51          [-1, 128, 32, 32]         262,144\n","      BatchNorm2d-52          [-1, 128, 32, 32]             256\n","             ReLU-53          [-1, 128, 32, 32]               0\n","     ResNeXtBlock-54          [-1, 128, 32, 32]               0\n","           Conv2d-55         [-1, 2048, 32, 32]         262,144\n","      BatchNorm2d-56         [-1, 2048, 32, 32]           4,096\n","             ReLU-57         [-1, 2048, 32, 32]               0\n","           Conv2d-58         [-1, 2048, 32, 32]       1,179,648\n","      BatchNorm2d-59         [-1, 2048, 32, 32]           4,096\n","             ReLU-60         [-1, 2048, 32, 32]               0\n","           Conv2d-61          [-1, 128, 32, 32]         262,144\n","      BatchNorm2d-62          [-1, 128, 32, 32]             256\n","             ReLU-63          [-1, 128, 32, 32]               0\n","     ResNeXtBlock-64          [-1, 128, 32, 32]               0\n","           Conv2d-65         [-1, 2048, 32, 32]         262,144\n","      BatchNorm2d-66         [-1, 2048, 32, 32]           4,096\n","             ReLU-67         [-1, 2048, 32, 32]               0\n","           Conv2d-68         [-1, 2048, 32, 32]       1,179,648\n","      BatchNorm2d-69         [-1, 2048, 32, 32]           4,096\n","             ReLU-70         [-1, 2048, 32, 32]               0\n","           Conv2d-71          [-1, 128, 32, 32]         262,144\n","      BatchNorm2d-72          [-1, 128, 32, 32]             256\n","             ReLU-73          [-1, 128, 32, 32]               0\n","     ResNeXtBlock-74          [-1, 128, 32, 32]               0\n","           Conv2d-75          [-1, 256, 16, 16]          32,768\n","      BatchNorm2d-76          [-1, 256, 16, 16]             512\n","           Conv2d-77         [-1, 4096, 32, 32]         524,288\n","      BatchNorm2d-78         [-1, 4096, 32, 32]           8,192\n","             ReLU-79         [-1, 4096, 32, 32]               0\n","           Conv2d-80         [-1, 4096, 16, 16]       4,718,592\n","      BatchNorm2d-81         [-1, 4096, 16, 16]           8,192\n","             ReLU-82         [-1, 4096, 16, 16]               0\n","           Conv2d-83          [-1, 256, 16, 16]       1,048,576\n","      BatchNorm2d-84          [-1, 256, 16, 16]             512\n","             ReLU-85          [-1, 256, 16, 16]               0\n","     ResNeXtBlock-86          [-1, 256, 16, 16]               0\n","           Conv2d-87         [-1, 4096, 16, 16]       1,048,576\n","      BatchNorm2d-88         [-1, 4096, 16, 16]           8,192\n","             ReLU-89         [-1, 4096, 16, 16]               0\n","           Conv2d-90         [-1, 4096, 16, 16]       4,718,592\n","      BatchNorm2d-91         [-1, 4096, 16, 16]           8,192\n","             ReLU-92         [-1, 4096, 16, 16]               0\n","           Conv2d-93          [-1, 256, 16, 16]       1,048,576\n","      BatchNorm2d-94          [-1, 256, 16, 16]             512\n","             ReLU-95          [-1, 256, 16, 16]               0\n","     ResNeXtBlock-96          [-1, 256, 16, 16]               0\n","           Conv2d-97         [-1, 4096, 16, 16]       1,048,576\n","      BatchNorm2d-98         [-1, 4096, 16, 16]           8,192\n","             ReLU-99         [-1, 4096, 16, 16]               0\n","          Conv2d-100         [-1, 4096, 16, 16]       4,718,592\n","     BatchNorm2d-101         [-1, 4096, 16, 16]           8,192\n","            ReLU-102         [-1, 4096, 16, 16]               0\n","          Conv2d-103          [-1, 256, 16, 16]       1,048,576\n","     BatchNorm2d-104          [-1, 256, 16, 16]             512\n","            ReLU-105          [-1, 256, 16, 16]               0\n","    ResNeXtBlock-106          [-1, 256, 16, 16]               0\n","          Conv2d-107         [-1, 4096, 16, 16]       1,048,576\n","     BatchNorm2d-108         [-1, 4096, 16, 16]           8,192\n","            ReLU-109         [-1, 4096, 16, 16]               0\n","          Conv2d-110         [-1, 4096, 16, 16]       4,718,592\n","     BatchNorm2d-111         [-1, 4096, 16, 16]           8,192\n","            ReLU-112         [-1, 4096, 16, 16]               0\n","          Conv2d-113          [-1, 256, 16, 16]       1,048,576\n","     BatchNorm2d-114          [-1, 256, 16, 16]             512\n","            ReLU-115          [-1, 256, 16, 16]               0\n","    ResNeXtBlock-116          [-1, 256, 16, 16]               0\n","          Conv2d-117         [-1, 4096, 16, 16]       1,048,576\n","     BatchNorm2d-118         [-1, 4096, 16, 16]           8,192\n","            ReLU-119         [-1, 4096, 16, 16]               0\n","          Conv2d-120         [-1, 4096, 16, 16]       4,718,592\n","     BatchNorm2d-121         [-1, 4096, 16, 16]           8,192\n","            ReLU-122         [-1, 4096, 16, 16]               0\n","          Conv2d-123          [-1, 256, 16, 16]       1,048,576\n","     BatchNorm2d-124          [-1, 256, 16, 16]             512\n","            ReLU-125          [-1, 256, 16, 16]               0\n","    ResNeXtBlock-126          [-1, 256, 16, 16]               0\n","          Conv2d-127         [-1, 4096, 16, 16]       1,048,576\n","     BatchNorm2d-128         [-1, 4096, 16, 16]           8,192\n","            ReLU-129         [-1, 4096, 16, 16]               0\n","          Conv2d-130         [-1, 4096, 16, 16]       4,718,592\n","     BatchNorm2d-131         [-1, 4096, 16, 16]           8,192\n","            ReLU-132         [-1, 4096, 16, 16]               0\n","          Conv2d-133          [-1, 256, 16, 16]       1,048,576\n","     BatchNorm2d-134          [-1, 256, 16, 16]             512\n","            ReLU-135          [-1, 256, 16, 16]               0\n","    ResNeXtBlock-136          [-1, 256, 16, 16]               0\n","          Conv2d-137            [-1, 512, 8, 8]         131,072\n","     BatchNorm2d-138            [-1, 512, 8, 8]           1,024\n","          Conv2d-139         [-1, 8192, 16, 16]       2,097,152\n","     BatchNorm2d-140         [-1, 8192, 16, 16]          16,384\n","            ReLU-141         [-1, 8192, 16, 16]               0\n","          Conv2d-142           [-1, 8192, 8, 8]      18,874,368\n","     BatchNorm2d-143           [-1, 8192, 8, 8]          16,384\n","            ReLU-144           [-1, 8192, 8, 8]               0\n","          Conv2d-145            [-1, 512, 8, 8]       4,194,304\n","     BatchNorm2d-146            [-1, 512, 8, 8]           1,024\n","            ReLU-147            [-1, 512, 8, 8]               0\n","    ResNeXtBlock-148            [-1, 512, 8, 8]               0\n","          Conv2d-149           [-1, 8192, 8, 8]       4,194,304\n","     BatchNorm2d-150           [-1, 8192, 8, 8]          16,384\n","            ReLU-151           [-1, 8192, 8, 8]               0\n","          Conv2d-152           [-1, 8192, 8, 8]      18,874,368\n","     BatchNorm2d-153           [-1, 8192, 8, 8]          16,384\n","            ReLU-154           [-1, 8192, 8, 8]               0\n","          Conv2d-155            [-1, 512, 8, 8]       4,194,304\n","     BatchNorm2d-156            [-1, 512, 8, 8]           1,024\n","            ReLU-157            [-1, 512, 8, 8]               0\n","    ResNeXtBlock-158            [-1, 512, 8, 8]               0\n","          Conv2d-159           [-1, 8192, 8, 8]       4,194,304\n","     BatchNorm2d-160           [-1, 8192, 8, 8]          16,384\n","            ReLU-161           [-1, 8192, 8, 8]               0\n","          Conv2d-162           [-1, 8192, 8, 8]      18,874,368\n","     BatchNorm2d-163           [-1, 8192, 8, 8]          16,384\n","            ReLU-164           [-1, 8192, 8, 8]               0\n","          Conv2d-165            [-1, 512, 8, 8]       4,194,304\n","     BatchNorm2d-166            [-1, 512, 8, 8]           1,024\n","            ReLU-167            [-1, 512, 8, 8]               0\n","    ResNeXtBlock-168            [-1, 512, 8, 8]               0\n","AdaptiveAvgPool2d-169            [-1, 512, 1, 1]               0\n","          Linear-170                   [-1, 10]           5,130\n","================================================================\n","Total params: 128,390,602\n","Trainable params: 128,390,602\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 1634.50\n","Params size (MB): 489.77\n","Estimated Total Size (MB): 2124.32\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yTVhZlPo8m-z"},"execution_count":null,"outputs":[]}]}