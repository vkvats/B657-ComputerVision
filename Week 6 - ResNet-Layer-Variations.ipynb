{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPraJ6kjeSST6KGQGxSvn8o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["## Imports\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"VR2QfRzaAY_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Original Residual Block (Standard ResNet)\n","class OriginalResidualBlock(nn.Module):\n","    \"\"\"Original ResNet design with BatchNorm and ReLU applied after each convolution.\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(OriginalResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","        return out"],"metadata":{"id":"ZhrRk2YLAY21","executionInfo":{"status":"ok","timestamp":1739294103246,"user_tz":300,"elapsed":2,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 2. BatchNorm After Addition\n","class BatchNormAfterAdditionResidualBlock(nn.Module):\n","    \"\"\"Batch Normalization is applied after the residual addition instead of before the activation.\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(BatchNormAfterAdditionResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.bn_out = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.bn_out(out)\n","        out = self.relu(out)\n","        return out"],"metadata":{"id":"U4lwD4rRAYzs","executionInfo":{"status":"ok","timestamp":1739294110570,"user_tz":300,"elapsed":4,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 3. ReLU Before Addition\n","class ReLUBeforeAdditionResidualBlock(nn.Module):\n","    \"\"\"ReLU is applied before the residual addition instead of after.\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ReLUBeforeAdditionResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out += identity\n","        return out"],"metadata":{"id":"RqgbYKVzAYvj","executionInfo":{"status":"ok","timestamp":1739294118877,"user_tz":300,"elapsed":5,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 4. ReLU-Only Pre-activation\n","class ReLUOnlyPreActivationResidualBlock(nn.Module):\n","    \"\"\"ReLU is applied before both convolutions without BatchNorm pre-activation.\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ReLUOnlyPreActivationResidualBlock, self).__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        x = self.relu(x)\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        return out"],"metadata":{"id":"Qt1xBaV-AiBh","executionInfo":{"status":"ok","timestamp":1739294129301,"user_tz":300,"elapsed":2,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1wUxLZYE_yJq","executionInfo":{"status":"ok","timestamp":1739294144021,"user_tz":300,"elapsed":2,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"outputs":[],"source":["# 5. Full Pre-Activation Residual Block\n","class FullPreActivationResidualBlock(nn.Module):\n","    \"\"\"Both BatchNorm and ReLU are applied before each convolution.\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(FullPreActivationResidualBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        out = self.bn1(x)\n","        out = self.relu1(out)\n","        if self.downsample is not None:\n","            identity = self.downsample(out)\n","        out = self.conv1(out)\n","        out = self.bn2(out)\n","        out = self.relu2(out)\n","        out = self.conv2(out)\n","        out += identity\n","        return out\n"]},{"cell_type":"code","source":["# Example Usage\n","example_input = torch.randn(1, 64, 32, 32)\n","blocks = [OriginalResidualBlock(64, 64), BatchNormAfterAdditionResidualBlock(64, 64),\n","          ReLUBeforeAdditionResidualBlock(64, 64), ReLUOnlyPreActivationResidualBlock(64, 64),\n","          FullPreActivationResidualBlock(64, 64)]\n","block_names = [\"Original\", \"Batch-Norm-After-Addition\", \"ReLU-Before-Addition\", \"ReLU-nly-Pre-Activation\", \"Full-Pre-Activation\"]\n","\n","for i, block in enumerate(blocks):\n","    output = block(example_input)\n","    print(f\"{block_names[i]} Output Shape: {output.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezeaaee8AC3V","executionInfo":{"status":"ok","timestamp":1739294147600,"user_tz":300,"elapsed":46,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}},"outputId":"893ac41c-e24c-43f3-e4c0-8a791c4342da"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Output Shape: torch.Size([1, 64, 32, 32])\n","Batch-Norm-After-Addition Output Shape: torch.Size([1, 64, 32, 32])\n","ReLU-Before-Addition Output Shape: torch.Size([1, 64, 32, 32])\n","ReLU-nly-Pre-Activation Output Shape: torch.Size([1, 64, 32, 32])\n","Full-Pre-Activation Output Shape: torch.Size([1, 64, 32, 32])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1NsDyS8hAR7D"},"execution_count":null,"outputs":[]}]}