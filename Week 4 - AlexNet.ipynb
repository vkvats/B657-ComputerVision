{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMzFK+bPLejTzFg23XXwfl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["## Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader"],"metadata":{"id":"Ic4vJNVM9FPe","executionInfo":{"status":"ok","timestamp":1738690076804,"user_tz":300,"elapsed":56,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## Equivalent of AlexNet\n","class AlexNet(nn.Module):\n","\n","    def __init__(self, num_classes=1000):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n"],"metadata":{"id":"bGakRdIW9LmD","executionInfo":{"status":"ok","timestamp":1738690077001,"user_tz":300,"elapsed":133,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","## Hyperparameters\n","batch_size = 64\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","## Data transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","## Load the Flowers-101 dataset\n","try:\n","    train_dataset = datasets.Flowers102(root='./data', split='train', download=True, transform=transform)\n","    val_dataset = datasets.Flowers102(root='./data', split='val', download=True, transform=transform)\n","except Exception as e:\n","    print(f\"Error loading Flowers102 dataset: {e}\")\n","    print(\"Please ensure you have the correct torchvision version and internet connectivity to download the dataset.\")\n","    exit()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","## Initialize the model, loss function, and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = AlexNet(num_classes=102).to(device) ## Flowers-101 has 102 classes\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","## Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    ## Validation loop\n","    model.eval()\n","    with torch.no_grad():\n","      correct = 0\n","      total = 0\n","      for images, labels in val_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","      accuracy = 100 * correct / total\n","      print(f\"Epoch [{epoch+1}/{num_epochs}], Val Accuracy: {accuracy:.4f}%\")\n"],"metadata":{"id":"EaS7aho49Wag"},"execution_count":null,"outputs":[]}]}