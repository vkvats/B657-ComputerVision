{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoQ73Vf01lewP/H3lEZrM+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from ipywidgets import interact, FloatSlider\n","from tqdm import tqdm\n"],"metadata":{"id":"M1J3hMMozo2n","executionInfo":{"status":"ok","timestamp":1739139773456,"user_tz":300,"elapsed":8486,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-_-RB70zoyv","executionInfo":{"status":"ok","timestamp":1739139792483,"user_tz":300,"elapsed":1072,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}},"outputId":"159b739a-5cdb-4414-9378-5cafb977387f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["\n","# ResNet Architecture Description:\n","\n","# 1. Input Layer:\n","#    - Receives the input image.\n","\n","# 2. Initial Convolutional Layer:\n","#    - A standard convolutional layer with a kernel size of 7x7 and stride of 2.\n","#    - Followed by batch normalization and a ReLU activation function.\n","#    - Reduces the spatial dimensions of the feature maps.\n","\n","# 3. Max Pooling Layer:\n","#    - Reduces the spatial dimensions further.\n","#    - Typically uses a kernel size of 3x3 and a stride of 2.\n","\n","# 4. Residual Blocks (Multiple):\n","#    - The core building blocks of ResNet.\n","#    - Each residual block contains two or more convolutional layers.\n","#    - A skip connection adds the input of the block to its output.\n","#    - This skip connection allows for the efficient flow of gradients during training.\n","#    - Different ResNet versions have varying numbers of residual blocks.\n","#    - Within a residual block:\n","#      - Convolutional layers with smaller kernel sizes (e.g., 3x3).\n","#      - Batch normalization and ReLU activation functions after each convolutional layer.\n","\n","# 5. Average Pooling Layer (Global Average Pooling):\n","#    - Reduces the spatial dimensions of the feature maps to a single value per channel.\n","#    - This is followed by a fully connected layer to get final classes.\n","\n","# 6. Fully Connected Layer:\n","#    - Maps the output of the average pooling layer to the number of classes.\n","#    - Produces the final classification probabilities or logits.\n","\n","\n","# The skip connections in the residual blocks are crucial for addressing the vanishing gradient problem\n","# during training of very deep networks. They enable the network to learn identity mappings, which helps\n","# in training deeper architectures effectively and avoids performance degradation.\n","\n"],"metadata":{"id":"5ztZhax26n9e"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8PzVJfNgzGaW","executionInfo":{"status":"ok","timestamp":1739139806954,"user_tz":300,"elapsed":13,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"outputs":[],"source":["# Define a Basic Residual Block\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","        return out\n","\n","# Define ResNet Model\n","class ResNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.layer1 = self._make_layer(3, 64, 2)\n","        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n","        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        layers = [ResidualBlock(in_channels, out_channels, stride, downsample)]\n","        for _ in range(1, blocks):\n","            layers.append(ResidualBlock(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x\n","\n"]},{"cell_type":"code","source":["# Instantiate model, loss, and optimizer\n","model = ResNet()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Interactive function for adjusting learning rate\n","def train_resnet(lr=0.001, epochs=5):\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    print(f\"Training ResNet with learning rate: {lr}\")\n","    for epoch in tqdm(range(epochs)):\n","        running_loss = 0.0\n","        for images, labels in trainloader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")\n","    print(\"Training Complete!\")"],"metadata":{"id":"gw2pe9mpzl3A","executionInfo":{"status":"ok","timestamp":1739139818448,"user_tz":300,"elapsed":200,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create an interactive slider\n","interact(train_resnet, lr=FloatSlider(min=0.0001, max=0.01, step=0.0001, value=0.001), epochs=(1, 10))"],"metadata":{"id":"WpGUSzn3zhwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization function for feature maps\n","def visualize_feature_maps():\n","    images, _ = next(iter(trainloader))\n","    model.eval()\n","    with torch.no_grad():\n","        activations = model.layer1(images[:1])  # Get activations from first ResNet block\n","    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n","    for i in range(5):\n","        axes[i].imshow(activations[0, i].cpu().numpy(), cmap='viridis')\n","        axes[i].axis('off')\n","    plt.show()\n","\n","visualize_feature_maps()"],"metadata":{"id":"BA0hSmpczJ8V"},"execution_count":null,"outputs":[]}]}