{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO46Aq0c46p/eNL7e8JjNpy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["## Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"metadata":{"id":"u1eFfhBCEFun","executionInfo":{"status":"ok","timestamp":1738691373286,"user_tz":300,"elapsed":9380,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### Networks basics"],"metadata":{"id":"p-ZrfspeEn01"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0izTKV5EA_9","executionInfo":{"status":"ok","timestamp":1738691373286,"user_tz":300,"elapsed":4,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}},"outputId":"bc7e3103-bb00-4b49-e14a-90b341dceff6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Output 1 shape: torch.Size([1, 10])\n","Output 2 shape: torch.Size([1, 5])\n","Loss 1: 2.350739002227783\n","Loss 2: 1.4947116374969482\n","Total loss: 2.093930721282959\n"]}],"source":["\n","class MultiSupervisionNetwork(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes1, num_classes2):\n","        super(MultiSupervisionNetwork, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2_1 = nn.Linear(hidden_size, num_classes1) ## Output for supervision signal 1\n","        self.fc2_2 = nn.Linear(hidden_size, num_classes2) ## Output for supervision signal 2\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        out1 = self.fc2_1(x) ## Output for the first classification task\n","        out2 = self.fc2_2(x) ## Output for the second classification task\n","        return out1, out2\n","\n","## Example usage\n","input_size = 784\n","hidden_size = 256\n","num_classes1 = 10\n","num_classes2 = 5\n","\n","model = MultiSupervisionNetwork(input_size, hidden_size, num_classes1, num_classes2)\n","input_tensor = torch.randn(1, input_size)  ## Example input (batch size 1)\n","\n","output1, output2 = model(input_tensor)\n","\n","print(\"Output 1 shape:\", output1.shape)\n","print(\"Output 2 shape:\", output2.shape)\n","\n","# Define loss functions (example: cross-entropy)\n","criterion1 = nn.CrossEntropyLoss()\n","criterion2 = nn.CrossEntropyLoss()\n","\n","## Example target values (replace with your actual targets)\n","target1 = torch.tensor([2]) ## Example target for the first task\n","target2 = torch.tensor([0]) ## Example target for the second task\n","\n","## Calculate losses\n","loss1 = criterion1(output1, target1)\n","loss2 = criterion2(output2, target2)\n","\n","## Combine losses (example: weighted sum)\n","total_loss = 0.7 * loss1 + 0.3 * loss2\n","\n","print(f\"Loss 1: {loss1}\")\n","print(f\"Loss 2: {loss2}\")\n","print(f\"Total loss: {total_loss}\")\n","\n","## Backpropagation and optimization would follow here\n","\n"]},{"cell_type":"code","source":["## Hyperparameters\n","input_size = 3 * 224 * 224 ## Example input size (adjust based on your image size and preprocessing)\n","hidden_size = 512\n","num_classes1 = 102  ## Number of classes for Flower-102 (or adjust)\n","num_classes2 = 10 ## Example second supervision (e.g., coarse-grained categories)\n","learning_rate = 0.001\n","num_epochs = 10\n","batch_size = 32\n","\n","## Data loading and preprocessing (Flower-102)\n","## Ensure you have the dataset downloaded correctly. If not, see torchvision documentation.\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ## Example normalization\n","])\n","\n","\n","## Create data loaders\n","train_dataset = datasets.Flowers102(root='./data', split='train', download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","\n","## Model, Loss functions, and Optimizer\n","model = MultiSupervisionNetwork(input_size, hidden_size, num_classes1, num_classes2)\n","criterion1 = nn.CrossEntropyLoss()\n","criterion2 = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","## Training loop\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        ## Reshape the image data\n","        data = data.view(-1, input_size) # Flatten the image data\n","\n","        ## Create dummy second target (replace with your second supervision signal)\n","        target2 = torch.randint(0, num_classes2, (target.size(0),))\n","\n","\n","        ## Forward pass\n","        output1, output2 = model(data)\n","        loss1 = criterion1(output1, target)\n","        loss2 = criterion2(output2, target2)  ## Replace target2 with actual second supervision\n","        total_loss = 0.8 * loss1 + 0.2 * loss2 ## Example weight combination\n","\n","        ## Backward pass and optimization\n","        optimizer.zero_grad()\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f\"Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss1: {loss1.item():.4f}, Loss2: {loss2.item():.4f}, Total Loss: {total_loss.item():.4f}\")"],"metadata":{"id":"K-IWikslEwBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c7Jl-m6WE9u-","executionInfo":{"status":"aborted","timestamp":1738691402386,"user_tz":300,"elapsed":2,"user":{"displayName":"Vibhas Vats","userId":"13570104701153014775"}}},"execution_count":null,"outputs":[]}]}