{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMK5E+JTFuymdTdTjwDTSdy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["## Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader"],"metadata":{"id":"UlC4lLWh9Ana"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## VGG-Net\n","class VGGNet(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(VGGNet, self).__init__()\n","        self.features = self._make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'])\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)\n"],"metadata":{"id":"TOoSaQWC8HgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","## Hyperparameters\n","batch_size = 64\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","## Data transformations (same as before)\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","## Load the Flowers-101 dataset (same as before)\n","try:\n","    train_dataset = datasets.Flowers102(root='./data', split='train', download=True, transform=transform)\n","    val_dataset = datasets.Flowers102(root='./data', split='val', download=True, transform=transform)\n","except Exception as e:\n","    print(f\"Error loading Flowers102 dataset: {e}\")\n","    print(\"Please ensure you have the correct torchvision version and internet connectivity to download the dataset.\")\n","    exit()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","## Initialize the VGGNet model, loss function, and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = VGGNet(num_classes=102).to(device)  ## Flowers-101 has 102 classes\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","## Training loop for VGGNet (same structure as AlexNet training loop)\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    ## Validation loop (same structure as AlexNet validation loop)\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        accuracy = 100 * correct / total\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Val Accuracy: {accuracy:.4f}%\")\n"],"metadata":{"id":"avI7Er_38fg6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"raEdqdT3_SaN"},"execution_count":null,"outputs":[]}]}